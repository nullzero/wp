#!/usr/bin/python
# -*- coding: utf-8 -*-

import sys, os, re
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

try: from lib import preload
except:
    print "เรียกใช้ไลบรารีไม่ได้ จบการทำงาน!"
    sys.exit()

import pwikipedia as pywikibot
from random import shuffle

def getlink(page, lim, reqen = False):
    page = pywikibot.Page(site, page)
    content = page.get()
    content = content.replace(u"'''", u"")
    candidates = []
    regex = ur"(?m)^[\*\#]+\s*\[\[(?!:en:)(.*?)(?:\|.*?)?\]\]"
    if reqen: regex += ur".*\[\[(:en:.*?)\]\]"
    for link in re.finditer(regex, content):
        if reqen: candidates.append((link.group(1), link.group(2)))
        else: candidates.append((link.group(1)))
    shuffle(candidates)
    count = 0
    out = []
    for link in candidates:
        if reqen: link, enlink = link
        if not pywikibot.Page(site, link).exists():
            if reqen:
                out.append(u"[[%s]][[%s|^]]" % (link, enlink))
            else:
                out.append(u"[[%s]]" % (link))
            count += 1
        if count == lim: break
    return out

def main():
    pagewrite = pywikibot.Page(site, u"แม่แบบ:ปรับปรุงล่าสุด/บทความที่ต้องการ")
    content = pagewrite.get()
    patlink = re.compile(ur"(?m)(?<=^--> )\[\[.*\]\](?= <!--$)")
    numlinks = len(patlink.findall(content))
    s = []
    s += getlink(u"วิกิพีเดีย:บทความที่ต้องการ", numlinks // 2, reqen = True)
    s += getlink(u"วิกิพีเดีย:รายชื่อบทความที่วิกิพีเดียทุกภาษาควรมี", numlinks - (numlinks // 2))
    for i in s: content = patlink.sub(i, content)
    pagewrite.put(content, u"ปรับปรุงรายการ")

if __name__ == "__main__":
    args, site = preload.pre(u"ปรับปรุงรายการบทความที่ต้องการ", lock = True)
    try: main()
    except: preload.posterror()
    preload.post()
