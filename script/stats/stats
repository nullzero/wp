#!/usr/bin/python
# -*- coding: utf-8 -*-

import sys, os
sys.path.append(os.path.abspath("../.."))
from lib import preload
from lib import libdata, re2
import pwikipedia as pywikibot, query, userlib

def _debug():
    allpages = libdata.LimitedSortedList(lambda a, b: b[0] - a[0])
    lim=10
    for page in site.allpages(includeredirects=False):
        pywikibot.output(u">>> %s" % page.title())
        allpages.append((page.quickCntRev(), page.title()))
        lim -=1
        if lim == 0:
            break
    lim=5
    for page in site.allpages(includeredirects=False, start=u"รายชื่อ"):
        pywikibot.output(u">>> %s" % page.title())
        allpages.append((page.quickCntRev(), page.title()))
        lim -=1
        if lim == 0:
            break
    return allpages.get()

"""
Begin helper function
"""

pageMain = None
contentMain = None

def firstContributor(title):
    name = pywikibot.Page(site, title).getCreator()[0]
    if userlib.User(site, name).isAnonymous():
        return u"-"
    else:
        return u"[[User:%s|%s]]" % (name, name)

def pagestat(): 
    allpages = libdata.LimitedSortedList(lambda a, b: b[0] - a[0])
    for page in site.allpages(includeredirects=False):
        pywikibot.output(u">>> %s" % page.title())
        allpages.append((page.quickCntRev(), page.title()))
    return allpages.get()

def getdat(regex):
    s = regex.find(contentMain)
    s = [x.strip() for x in s.split(u"|-")]
    table = []
    for line in s:
        line = line.strip()
        if line.startswith(u"|}"):
            break
        if not line.startswith(u"|"):
            continue
        table.append([x.strip() for x in line.split(u"||")])
    
    for i in xrange(len(table)):
        table[i][0] = re2.patWikilink.find(table[i][0])
    
    return table

def tag(x):
    if x == 0:
        return conf.same
    elif x < 0:
        return conf.inc
    else:
        return conf.dec

def writetable(table, regex):
    global contentMain
    for i in xrange(len(table)):
        table[i][0] = u"%s %d. [[%s]]" % (tag(i + 1 - table[i][1]), 
                                            i + 1, table[i][0])
        if table[i][1] == sys.maxint:
            table[i][1] = conf.newcomer
        table[i] = u" || ".join([unicode(x) for x in table[i]])
    contentMain = regex.sub(u"".join(map(lambda x: u"\n|-\n| " + x, table))
                        u"\n|}\n{{hatnote|" + conf.summary + u" %s}}\n" % 
                        preload.getTime(), contentMain)

def flush():
    print contentMain
    #pageMain.put(contentMain, conf.summary)

def getrankold(title, table):
    for i, val in enumerate(table):
        if val[0] == title:
            return i + 1
    return sys.maxint

"""
End helper function
"""

def mosteditsArt():
    """
    most edits
    """
    regexArt = re2.genData(conf.tagind, u"บทความแก้ไขมากสุด")
    regexArtlist = re2.genData(conf.tagind, u"บทความรายชื่อแก้ไขมากสุด")
    oldtable = getdat(regexArt)
    oldtablelist = getdat(regexArtlist)
    table = []
    tablelist = []
    ptr = 0
    patListName = re2.re2(re2.sep(conf.listname))
    #allpages = pagestat()
    allpages = _debug()
    while True:
        if (len(tablelist) < 5) and patListName.search(allpages[ptr][1]):
            tablelist.append([allpages[ptr][1], getrankold(allpages[ptr][1],
                                                            oldtablelist), 
                        allpages[ptr][0], firstContributor(allpages[ptr][1])])
        elif len(table) < 10 and (not patListName.search(allpages[ptr][1])):
            table.append([allpages[ptr][1], getrankold(allpages[ptr][1], 
                                                        oldtable), 
                        allpages[ptr][0], firstContributor(allpages[ptr][1])])
        elif (len(tablelist) >= 5) and (len(table) >= 10):
            break
        ptr += 1
            
    writetable(table, regexArt)
    writetable(tablelist, regexArtlist)
    
def longpages():
    """
    long pages
    """
    table = []
    regexLong = re2.genData(conf.tagind, u"บทความยาวสุด")
    oldlongpages = getdat(regexLong)
    for page, length in site.longpages(5):
        table.append([page.title(), getrankold(page.title(), oldlongpages),
                    length])
    writetable(table, regexLong)
    
def mosteditsUser():
    """
    most edits (user)
    """
    limit = re2.getconf(u"ตารางชาววิกิพีเดียที่เขียนมากที่สุด", contentMain)
    regexUser = re2.genData(conf.tagind, u"ชาววิกิพีเดียที่เขียนมากที่สุด")
    oldusers = getdat(regexUser)
    table = []
    for line in pywikibot.Page(site, conf.page500).get().split("\n"):
        libe = line.strip()
        if line == u"|-":
            continue
        if line.startswith(u"|"):
            line = [x.strip() for x in line[1:].split(u"||")]
            name = re2.patWikilink.find(line[1])
            cnt = re2.find(u"(?<=\|)\d+(?=\]\])", line[2])
            if int(cnt) < int(limit): break
            table.append([name, getrankold(name, oldusers), cnt])
    writetable(table, regexUser)
    
def main():
    global pageMain, contentMain
    pageMain = pywikibot.Page(site, u"วิกิพีเดีย:ที่สุดในวิกิพีเดียภาษาไทย")
    contentMain = pageMain.get()
    mosteditsArt()
    longpages()
    mosteditsUser()
    flush()
    
if __name__ == "__main__":
    args, site, conf = preload.pre(u"update top things in Wikipedia")
    try:
        #_debug()
        main()
    except:
        preload.posterror()
    else:
        preload.post()
